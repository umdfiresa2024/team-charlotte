---
title: "Team Charlotte Weekly Report"
author: "Adityaraj Padmanabhna & David Guan"
format: gfm
editor: visual
---

## Research Question

1.  Does the introduction of light rails affect the particulate matter (PM2.5) levels in Charlotte, North Carolina?
2.  Do different income brackets have different levels of reduction after introducing light rails?

## Hypothesis

1.  Light Rail opening:
    -   Null Hypothesis (H₀): The introduction of light rails has no effect on particulate matter (PM2.5) levels in Charlotte, North Carolina.​

    -   Alternative Hypothesis (H~A~): The introduction of light rails has an effect on particulate matter (PM2.5) levels in Charlotte, North Carolina.
2.  Income:
    -   Null Hypothesis (H₀): There is no difference in the levels of PM2.5 reduction across different income brackets after introducing light rails.

    -   Alternative Hypothesis (H~A~): There is a difference in the levels of PM2.5 reduction across different income brackets after introducing light rails.

## Context

-   Area of study: Blue Lynx Light Rail, Charlotte, North Caroline

    -   Table with corresponding above stations

        ```{r}
        library("knitr")

        stations_table <- read.csv("new_station_coords_data.csv")
        kable(stations_table)
        ```

-   Time Frame: November 2003 - November 2011

-   Factors associated with PM2.5

    -   Airport

    -   Power Plant(s)

    -   Factories

    -   Major Intersection

        -   Table with corresponding above factors

            ```{r}
            factors_table <- read.csv("new_pm_coords_data.csv")
            kable(factors_table)
            ```

## Cleaning & Combining Data

### Installing Packages

```{r}
#| eval: false
# install.packages("tidyverse")
# install.packages("ggmap")
# install.packages("maptiles")
# install.packages("terra")
# install.packages("leaflet")
# install.packages("tidycensus)
# install.packages("RColorBrewer")
```

### Loading Libraries

```{r}
#| warning: false
#| message: false
library("tidyverse")
library("ggmap")
library("terra")
library("maptiles")
library("leaflet")
library("tidycensus")
library("RColorBrewer")
```

Gathered Data using Google API

We utilized the Google Maps API to obtain the coordinates (latitude and longitude) and the exact addresses of all the stations mentioned in our dataset. This process involved sending requests to the Google Maps API with station names and receiving detailed geolocation data in response.

However, due to GitHub's policies on not publicly sharing API keys, we have not included the API key directly in our repository. Instead, we have preprocessed the data and saved the geocoded results in a CSV file named "new_station_coords_data.csv"

Cleaning Data

```{r}
addrs.geo <- read.csv("new_station_coords_data.csv")
new_addr <- addrs.geo %>% 
  mutate(
    lat2 = ifelse(
      stations == "Bland Street station", 
      35.21622, 
      lat
    ), 
    lon2 = ifelse(
      stations == "Bland Street station", 
      -80.85446, 
      lon
    ),
    address2 = ifelse(
      stations == "Bland Street station", 
      "1511 Camden Road, charlotte, nc, usa", address
      
    )
  ) %>% 
  mutate(
    lat2 = ifelse(
      stations == "Carson light rail station (Charlotte)", 
      35.21944, 
      lat2
    ), 
    lon2 = ifelse(
      stations == "Carson light rail station (Charlotte)", 
      -80.84823, 
      lon2
    ),
    address2 = ifelse(
      stations == "Carson light rail station (Charlotte)", 
      "218 East Carson Boulevard, charlotte, nc, usa",
      address2
    )
  ) %>% 
  mutate(
    lat2 = ifelse(
      stations == "Charlotte Transportation Center", 
      35.21944, 
      lat2
    ), 
    lon2 = ifelse(
      stations == "Charlotte Transportation Center", 
      -80.84823, 
      lon2
    ),
    address2 = ifelse(
      stations == "Charlotte Transportation Center", 
      "310 East Trade Street, charlotte, nc, usa", address2 
    )
  ) %>% 
  
  
  mutate(
    lat2 = ifelse(
      stations == "JW Clay Blvd/UNC Charlotte station", 
      35.31155, 
      lat2
    ), 
    lon2 = ifelse(
      stations == "JW Clay Blvd/UNC Charlotte station", 
      -80.74547, 
      lon2
    ),
    address2 = ifelse(
      stations == "JW Clay Blvd/UNC Charlotte station", 
      "9048 North Tryon Street, charlotte, nc, usa", address2 
    )
  )
```

Storing Data into new CSV File

```{r}
#| eval: false
# First time users - do NOT over-wrrite CSV file
# write.csv(new_addr, "new_station_coords_data.csv", row.names = FALSE)
```

Storing Latitude and Longtitude

```{r}
sample_latlon <- cbind(new_addr$lon2, new_addr$lat2)
```

Storing into Vector Data

```{r}
pts <-  vect(sample_latlon)
crdref <- "+proj=longlat +datum=WGS84"
pts <- vect(sample_latlon, crs=crdref)
plot(pts)
```

### Overlaying Stations with PM2.5

```{r}
# Plot Stations
x <- vect(sample_latlon, crs = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")

# Plot Factors
pm_sources <- vect("/Users/paditya9/teamCharlotte/PM2.5 ShapeFiles/new_pm_coords_sources.shp")
plot(pm_sources)

# Plot Buffer around stations
# Target Buffer Radius =  800 meters
pts_buffer <- buffer(x, width = 800)

# Creating Buffer for Map
extent<-buffer(x, width = 200)

bg <- get_tiles(ext(extent), zoom = 11)

# Plots the background
plot(bg)

# pch=19 gives filled circles
points(x, col="blue", pch=19, cex=0.5)

# pch=17 gives filled triangles
points(pm_sources, col="purple", pch=17, cex=1)

# Plot the buffer around the stations
lines(pts_buffer, col="red")
```

Saving the Buffer's into ShapeFile

```{r}
# First time users - do NOT over-wrrite CSV file
# writeVector(pts_buffer, "new_buffer_light_rail.shp")
```

### Combining PM2.5 Daily Data

```{r}
# List all CSV files in the directory
file_list <- list.files(path = "PM25_daily", pattern = "*.csv", full.names = TRUE)

# Read and combine all CSV files into one data frame
combined_df <- do.call(rbind, lapply(file_list, function(file) {
  df <- read.csv(file)
  # Assuming your date column is named 'date' and is in format '%Y%m%d'
  df$date <- as.Date(df$date, format = "%Y%m%d")
  df
}))

# Filter rows from 2003-11-24 to 2011-11-24
combined_df_filtered <- combined_df %>%
  filter(date >= as.Date("2003-11-24") & date <= as.Date("2011-11-24"))

# Write the filtered data frame to a new CSV file
write.csv(combined_df_filtered, "refined_PM25_daily_combined_data.csv", row.names = FALSE)

PM_25_with_date <- read.csv("refined_PM25_daily_combined_data.csv")

PM_25_with_date <- PM_25_with_date %>%
   mutate(formatted_date = paste(substr(date, 1, 4), substr(date, 6, 7), substr(date, 9, 10), sep = "-")) %>% mutate(station_ID = PM_25_with_date$city_num )

# First time users - do NOT over-wrrite CSV file
# write.csv(PM_25_with_date, "refined_date_PM25_daily_data.csv")

```

Creating Station ID

```{r}
stations_coords <- read.csv("/Users/paditya9/teamCharlotte/new_station_coords_data.csv")

stations_coords <- stations_coords %>% mutate(station_ID = row_number())

# First time users - do NOT over-wrrite CSV file
# write.csv(stations_coords, "station_coords_with_stationID_data.csv", row.names = F)
```

Creating Holiday Data

```{r}
holidays_data <- read.csv("/Users/paditya9/teamCharlotte/major_holidays_2000_2025.csv", header = TRUE, stringsAsFactors = FALSE)

holidays_data <- holidays_data %>% filter(date >= as.Date("2003-11-24") & date <= as.Date("2011-11-24")) %>% mutate(formatted_date = date)

# First time users - do NOT over-wrrite CSV file
# write.csv(holidays_data, "refined_holidays_data.csv", row.names = F)
```

Cumulative Data

This code chunk combines various data frames into a single data frame, emphasizing code re usability and avoiding complexity. It integrates data from below CSV files

1.  Stations Data
2.  PM2.5 measurements Data
3.  Meteorological Data
4.  Holidays Data

```{r}
#| message: false
#Reading Stations Data
stationID_data <- read.csv("station_coords_with_stationID_data.csv", header = TRUE, stringsAsFactors = FALSE)[, c("stations", "station_ID", "address2")]

#Reading PM2.5 Daily Data
pm_25_data <- read.csv("refined_date_PM25_daily_data.csv", header = TRUE, stringsAsFactors = FALSE)[, c("station_ID", "formatted_date", "pm25")]

#Reading Meterological Data
met_data <- read.csv("met_data_charlotte/combinedMeteorologyDataCharlotte.csv", header = TRUE, stringsAsFactors = FALSE)[, c("Tair_f_tavg", "Wind_f_tavg", "Qair_f_tavg", "formatted_date")]

#Reading Holiday Data
holidays_data <- read.csv("/Users/paditya9/teamCharlotte/refined_holidays_data.csv", header = TRUE, stringsAsFactors = FALSE)[, c("holiday", "formatted_date")]

station_pm_met_dataCombined <- merge(stationID_data,pm_25_data, by="station_ID", all = F )

station_pm_met_dataCombined <- merge(station_pm_met_dataCombined, met_data, by="formatted_date", all = F)

station_pm_met_holiday_dataCombined <- station_pm_met_dataCombined %>% left_join(holidays_data, by = "formatted_date", keep = FALSE, unmatched = "drop")


# Ordering the list by date followed by station ID
station_pm_met_holiday_dataCombined_order <- station_pm_met_holiday_dataCombined[order(station_pm_met_holiday_dataCombined$formatted_date, station_pm_met_holiday_dataCombined$station_ID), ]

# %B is used for abbrevation for Month 
station_pm_met_holiday_dataCombined_formatted <- station_pm_met_holiday_dataCombined_order %>%
  mutate(month = format(as.Date(station_pm_met_holiday_dataCombined_order$formatted_date, format = "%Y-%m-%d"), "%B")) %>% 
  mutate (day_of_week = weekdays(as.Date(station_pm_met_holiday_dataCombined_order$formatted_date, format = "%Y-%m-%d"))) %>% 
# NA = 0; Holiday = 1
  mutate(holiday_binary = ifelse(is.na(holiday), 0, 1))

# First time users - do NOT over-wrrite CSV file
# write_csv(station_pm_met_holiday_dataCombined_formatted, "station_pm_met_holiday_dataCombined_formatted.csv")
```

```{r}
combinedData <- read.csv("station_pm_met_holiday_dataCombined_formatted.csv")

# No PM sources = 0; PM Source near Station = 1
binaryPMFactor <- combinedData %>% 
  mutate(control_variables = ifelse(
    station_ID %in% c(5, 6, 9, 10), 1, 0
  ))

# write.csv(binaryPMFactor, "station_pm_met_holiday_dataCombined_formatted.csv" )
```

Adding Binary Column for PM Factor's The

-   Total Observations = 76,000

-   Total Variables = 25

-   Variable Description

    -   1\. Station ID = Unique identifier for each light rail station (Range: 1-26)

    -   2\. formatted_date = The date when the measurement was recorded, formatted as YYYY-MM-DD.

    -   3\. stations = Name of the light rail station.

    -   4\. address2 = Full address of the light rail station.

    -   5\. pm25 = Measured particulate matter (PM2.5) concentration in the air.

    -   6\. Swnet_tavg = Net short wave radiation flux.

    -   7\. Lwnet_tavg = Net long-wave radiation flux.

    -   8\. Qle_tavg = Latent heat net flux.

    -   9\. Qh_tavg = Sensible heat net flux.

    -   10\. Snowf_tavg = Snow precipitation rate.

    -   11\. Rainf_tavg = Rain precipitation rate.

    -   12\. Qsm_tavg = Snow melt.

    -   13\. SnowT_tavg = Snow Surface temperature.

    -   14\. SWE_tavg = Snow depth water equivalent.

    -   15\. SnowDepth_tavg = Snow depth.

    -   16\. Tair_f_tavg = Temperature.

    -   17\. Rainf_f_tavg = Total precipitation rate.

    -   18\. Wind_f_tavg = Wind speed.

    -   19\. Qair_f_tavg = Specific humidity.

    -   20\. Psurf_f_tavg = Pressure.

    -   21\. Parking = Binary indicator for the presence of parking facilities at the station (1 for presence, 0 for absence).

    -   22\. holiday_binary = Binary indicator for whether the date is a holiday (1 for holiday, 0 for non-holiday).

    -   23\. month = Month of the year when the measurement was recorded.

    -   24\. day_of_week = Day of the week when the measurement was recorded.

    -   25\. PMFactor = Factor variable for PM2.5 levels, possibly indicating an adjusted or categorized value.

```{r}
combinedData_table <- read.csv("station_pm_met_holiday_dataCombined_formatted.csv")
head(combinedData_table) %>%
  kable()


```

### Regression Model Calculation

```{r}
df <-read.csv("station_pm_met_holiday_dataCombined_formatted.csv")

df2 <- df %>% mutate(date = as.Date(formatted_date,format = "%Y-%m-%d"))


startdate <- as.Date("2003-11-24",format = "%Y-%m-%d")

enddate <- as.Date("2011-11-24",format = "%Y-%m-%d")

opendate <- as.Date("2007-11-24",format = "%Y-%m-%d")

constructionstart <- as.Date("2005-02-26",format = "%Y-%m-%d")

CAIR <- as.Date("2005-03-10",format = "%Y-%m-%d")

metroOpen_df <- df2 %>% filter(date >= startdate & date<=enddate)%>%
  mutate(MetroOpen = ifelse(date>=opendate,1,0))%>%
  mutate(construction = ifelse(date>=constructionstart & date<opendate,1,0))%>%
  mutate(duringCAIR = ifelse(date>=CAIR & date<= enddate,1,0))%>%
  group_by(station_ID)%>%
  arrange(date, station_ID)%>%
  mutate(lTair_f_tavg = lag(Tair_f_tavg))%>%
  mutate(lQair_f_tavg = lag(Qair_f_tavg)) %>%
  mutate(lPsurf_f_tavg = lag(Psurf_f_tavg)) %>%
  mutate(lWind_f_tavg = lag(Wind_f_tavg)) %>%
  mutate(t=as.numeric(date-startdate))%>%
  mutate(t2 = t^2,t3=t^3,t4=t^4)

regression_stats <- summary(m1 <- lm(log(pm25)~MetroOpen+construction+duringCAIR+as.factor(day_of_week)+as.factor(month) + Tair_f_tavg + Swnet_tavg + Lwnet_tavg + Qle_tavg + Qh_tavg + Snowf_tavg + Rainf_tavg + Qsm_tavg + SnowT_tavg + SWE_tavg + SnowDepth_tavg + Tair_f_tavg + Rainf_f_tavg + Wind_f_tavg + Qair_f_tavg + Psurf_f_tavg + Parking + Parking:MetroOpen, data = metroOpen_df))

df2 <- df %>% 
  mutate(date = as.Date(formatted_date, format = "%Y-%m-%d"))

# Define dates
startdate <- as.Date("2003-11-24", format = "%Y-%m-%d")
enddate <- as.Date("2011-11-24", format = "%Y-%m-%d")
opendate <- as.Date("2007-11-24", format = "%Y-%m-%d")
constructionstart <- as.Date("2005-02-26", format = "%Y-%m-%d")
CAIR <- as.Date("2005-03-10", format = "%Y-%m-%d")

# Filter and mutate the data
metroOpen_df <- df2 %>% 
  filter(date >= startdate & date <= enddate) %>%
  mutate(
    MetroOpen = ifelse(date >= opendate, 1, 0),
    construction = ifelse(date >= constructionstart & date < opendate, 1, 0),
    duringCAIR = ifelse(date >= CAIR & date <= enddate, 1, 0)
  ) %>%
  group_by(station_ID) %>%
  arrange(date, station_ID) %>%
  mutate(
    lTair_f_tavg = lag(Tair_f_tavg),
    lQair_f_tavg = lag(Qair_f_tavg),
    lPsurf_f_tavg = lag(Psurf_f_tavg),
    lWind_f_tavg = lag(Wind_f_tavg),
    t = as.numeric(date - startdate),
    t2 = t^2,
    t3 = t^3,
    t4 = t^4
  )

# Perform regression
regression_stats <- summary(
  m1 <- lm(
    log(pm25) ~ MetroOpen + construction + duringCAIR + as.factor(day_of_week) + as.factor(month) +
    Tair_f_tavg + Swnet_tavg + Lwnet_tavg + Qle_tavg + Qh_tavg + Snowf_tavg + Rainf_tavg + 
    Qsm_tavg + SnowT_tavg + SWE_tavg + SnowDepth_tavg + Tair_f_tavg + Rainf_f_tavg + 
    Wind_f_tavg + Qair_f_tavg + Psurf_f_tavg + Parking + Parking:MetroOpen,
    data = metroOpen_df
  )
)

pal <- brewer.pal(n=4,name = "RdBu")
df3 <- df2 %>% 
  group_by(date) %>% summarize(mean_pm25 = mean(pm25)) %>%
mutate(before_after = ifelse(date < opendate, "Before", "After"))

ggplot(df3, aes(x = date, y = mean_pm25, color = before_after))+
  
  geom_rect(aes(xmin = constructionstart,xmax = opendate, ymin = -Inf, ymax = Inf), alpha = 1, fill = "gray") +scale_color_manual(values = pal[3:4])+
  
  
  geom_point() +
  geom_smooth( color = "blue")+
  # facet_wrap(~ station_ID, scales = "free_y") +  # Facet by station_ID
  labs(
    x = "Date",
    y = "Average PM2.5 levels across stations",
    color = "Metro Opening"
  ) +
  
  theme_minimal()+geom_vline(xintercept = opendate, linetype = "dashed")+geom_vline(xintercept = CAIR, linetype = "dashed")
```

### Regression Testing

DB-OLS Regression Table

 

|                                  |             |
|----------------------------------|-------------|
|                                  | Log(PM2.5)  |
| Factors                          | \(1\)       |
| MetroOpen                        | -0.26\*\*\* |
| Construction Dummy               |             |
| Day of Week Fixed Effects        |             |
| Month Fixed Effects              |             |
| Temperature, Wind, Humidity      |             |
| Holiday Binary                   |             |
| All Other Weather Controls       |             |
| Clean Air Interstate Rule Binary |             |

### Calculating Station level pollution change

Station-level effect and the p-values

```{r}
c<- coef(m1)
len_coef<-length(coef(m1))

#get coefficients of the station-level effect
coef<-coef(m1)[(len_coef-(26-1)): len_coef]

#get p values of the station-level effect (p<0.05 is statistically significant)
pval<-summary(m1)$coefficients[,4][(len_coef-3): len_coef]

kable(cbind(coef, pval), digits=2)
```

### Census Data

Using American Census Survey (ACS) Data

```{r}
vars<-load_variables(year=2010, dataset="acs1", cache = TRUE)


write.csv(vars, "demographics_variable_acs.csv")
```

### Interest Variable - Income

We hypothesize that lower-income individuals live closer to metro rail lines and high-density urban areas, leading to higher PM2.5 exposure. Conversely, higher-income individuals likely reside in suburban areas, using private transportation and experiencing lower PM2.5 exposure.

The variable "targetvars" stores all the different income brackets from the demographics file that was retreieved.

```{r}
#vars range from less than 10k to more than 200k

targetvars <- c("B19001_001", "B19001_002", "B19001_003", "B19001_004", "B19001_005", 
                "B19001_006", "B19001_007", "B19001_008", "B19001_009", "B19001_010", 
                "B19001_011", "B19001_012", "B19001_013", "B19001_014", "B19001_015", 
                "B19001_016", "B19001_017")

income<-get_acs(geography = "tract", variables=targetvars, state="NC", county="Mecklenburg", output="wide", year = 2010) %>% select(-ends_with("M"))

#the variables that end in E are the estimates while the ones that end in M tell the margin of error.

income_name<-income %>%
  rename(total = B19001_001E, 
       less_than_10k = B19001_002E, 
       `10k_to_15k` = B19001_003E, 
       `15k_to_20k` = B19001_004E, 
       `20k_to_25k` = B19001_005E, 
       `25k_to_30k` = B19001_006E, 
       `30k_to_35k` = B19001_007E, 
       `35k_to_40k` = B19001_008E, 
       `40k_to_45k` = B19001_009E, 
       `45k_to_50k` = B19001_010E, 
       `50k_to_60k` = B19001_011E, 
       `60k_to_75k` = B19001_012E, 
       `75k_to_100k` = B19001_013E, 
       `100k_to_125k` = B19001_014E, 
       `125k_to_150k` = B19001_015E, 
       `150k_to_200k` = B19001_016E, 
       `200k_or_more` = B19001_017E)
```

### Reading Buffer Files

```{r}
#| output: false
buff<-vect("Buffer Light Rail/new_buffer_light_rail.shp")
shape<-tigris::tracts(state="NC", county="Mecklenburg", class="sp", year=2010)
shapevect<-vect(shape)
shapedf<-as.data.frame(shape)
```

### Summary Statistics of Income

```{r}
tract_income<-merge(shapevect, income_name, by.x="GEOID10", by.y="GEOID")

tract_income$tract_area<-expanse(tract_income, unit="m")

tract_income_df<-as.data.frame(tract_income)

summary(tract_income_df)
```

Inserting blocks with buffer

This code chunk examines the demographic distribution and environmental benefits of light rail stations in Charlotte, NC. The code processes spatial data to:

1.  Calculate the fraction of each income bracket within buffer zones around light rail stations, scaling population data based on the area of overlap between census tracts and buffers.
2.  Compute changes in pollution levels due to light rail stations, estimating the total impact across all stations. The average pollution reduction for each income bracket is calculated, highlighting the benefits for different demographic groups.
3.  Present the results in a summary table, showing the average pollution reduction experienced by individuals in each income bracket.

```{r}
buffdf <- as.data.frame(buff)

output <- c()

for(i in 0:25){
  print(i)

buff2 <- subset(buff,buff$FID ==i)

int<-crop(tract_income, buff2)

int$intarea<-expanse(int, unit="m")



intdf<-as.data.frame(int)%>%

  mutate(frac_area=intarea/tract_area) %>%
  mutate(total=total*frac_area, 
         
         
         
        `less_than_10k` = `less_than_10k` * frac_area,
`10k_to_15k` = `10k_to_15k` * frac_area,
`15k_to_20k` = `15k_to_20k` * frac_area,
`20k_to_25k` = `20k_to_25k` * frac_area,
`25k_to_30k` = `25k_to_30k` * frac_area,
`30k_to_35k` = `30k_to_35k` * frac_area,
`35k_to_40k` = `35k_to_40k` * frac_area,
`40k_to_45k` = `40k_to_45k` * frac_area,
`45k_to_50k` = `45k_to_50k` * frac_area,
`50k_to_60k` = `50k_to_60k` * frac_area,
`60k_to_75k` = `60k_to_75k` * frac_area,
`75k_to_100k` = `75k_to_100k` * frac_area,
`100k_to_125k` = `100k_to_125k` * frac_area,
`125k_to_150k` = `125k_to_150k` * frac_area,
`150k_to_200k` = `150k_to_200k` * frac_area,
`200k_or_more` = `200k_or_more` * frac_area
         
         ) %>%
  summarize(total=sum(total), 
            
            
            `less_than_10k` = sum(`less_than_10k`),
`10k_to_15k` = sum(`10k_to_15k`),
`15k_to_20k` = sum(`15k_to_20k`),
`20k_to_25k` = sum(`20k_to_25k`),
`25k_to_30k` = sum(`25k_to_30k`),
`30k_to_35k` = sum(`30k_to_35k`),
`35k_to_40k` = sum(`35k_to_40k`),
`40k_to_45k` = sum(`40k_to_45k`),
`45k_to_50k` = sum(`45k_to_50k`),
`50k_to_60k` = sum(`50k_to_60k`),
`60k_to_75k` = sum(`60k_to_75k`),
`75k_to_100k` = sum(`75k_to_100k`),
`100k_to_125k` = sum(`100k_to_125k`),
`125k_to_150k` = sum(`125k_to_150k`),
`150k_to_200k` = sum(`150k_to_200k`),
`200k_or_more` = sum(`200k_or_more`)
            
            
            
            ) %>%
  mutate(
    
    
   `pct_less_than_10k` = `less_than_10k` * 100 / `total`,
`pct_10k_to_15k` = `10k_to_15k` * 100 / `total`,
`pct_15k_to_20k` = `15k_to_20k` * 100 / `total`,
`pct_20k_to_25k` = `20k_to_25k` * 100 / `total`,
`pct_25k_to_30k` = `25k_to_30k` * 100 / `total`,
`pct_30k_to_35k` = `30k_to_35k` * 100 / `total`,
`pct_35k_to_40k` = `35k_to_40k` * 100 / `total`,
`pct_40k_to_45k` = `40k_to_45k` * 100 / `total`,
`pct_45k_to_50k` = `45k_to_50k` * 100 / `total`,
`pct_50k_to_60k` = `50k_to_60k` * 100 / `total`,
`pct_60k_to_75k` = `60k_to_75k` * 100 / `total`,
`pct_75k_to_100k` = `75k_to_100k` * 100 / `total`,
`pct_100k_to_125k` = `100k_to_125k` * 100 / `total`,
`pct_125k_to_150k` = `125k_to_150k` * 100 / `total`,
`pct_150k_to_200k` = `150k_to_200k` * 100 / `total`,
`pct_200k_or_more` = `200k_or_more` * 100 / `total`
    
    
    
    )%>% mutate(FID = i)
output <- rbind(output,intdf)
}
  
```

Summarize demographic groups that live near light rail stations

```{r}
sum_demog<-output %>%
  #combinging all the station's data together
  summarize(total = sum(total),
   `less_than_10k` = sum(`less_than_10k`),
`10k_to_15k` = sum(`10k_to_15k`),
`15k_to_20k` = sum(`15k_to_20k`),
`20k_to_25k` = sum(`20k_to_25k`),
`25k_to_30k` = sum(`25k_to_30k`),
`30k_to_35k` = sum(`30k_to_35k`),
`35k_to_40k` = sum(`35k_to_40k`),
`40k_to_45k` = sum(`40k_to_45k`),
`45k_to_50k` = sum(`45k_to_50k`),
`50k_to_60k` = sum(`50k_to_60k`),
`60k_to_75k` = sum(`60k_to_75k`),
`75k_to_100k` = sum(`75k_to_100k`),
`100k_to_125k` = sum(`100k_to_125k`),
`125k_to_150k` = sum(`125k_to_150k`),
`150k_to_200k` = sum(`150k_to_200k`),
`200k_or_more` = sum(`200k_or_more`))%>%
  mutate(`pct_less_than_10k` = `less_than_10k` * 100 / `total`,
`pct_10k_to_15k` = `10k_to_15k` * 100 / `total`,
`pct_15k_to_20k` = `15k_to_20k` * 100 / `total`,
`pct_20k_to_25k` = `20k_to_25k` * 100 / `total`,
`pct_25k_to_30k` = `25k_to_30k` * 100 / `total`,
`pct_30k_to_35k` = `30k_to_35k` * 100 / `total`,
`pct_35k_to_40k` = `35k_to_40k` * 100 / `total`,
`pct_40k_to_45k` = `40k_to_45k` * 100 / `total`,
`pct_45k_to_50k` = `45k_to_50k` * 100 / `total`,
`pct_50k_to_60k` = `50k_to_60k` * 100 / `total`,
`pct_60k_to_75k` = `60k_to_75k` * 100 / `total`,
`pct_75k_to_100k` = `75k_to_100k` * 100 / `total`,
`pct_100k_to_125k` = `100k_to_125k` * 100 / `total`,
`pct_125k_to_150k` = `125k_to_150k` * 100 / `total`,
`pct_150k_to_200k` = `150k_to_200k` * 100 / `total`,
`pct_200k_or_more` = `200k_or_more` * 100 / `total`)

kable(sum_demog, digits=2)

# Calculate the reduction benefit
# Multiplying the number of people in each demographic by the change in pollution caused by light rail
reduction_benefit <- everything %>%mutate(total_change = total * coef,
    `less_than_10k_change` = `less_than_10k` * coef,
    `10k_to_15k_change` = `10k_to_15k` * coef,
    `15k_to_20k_change` = `15k_to_20k` * coef,
    `20k_to_25k_change` = `20k_to_25k` * coef,
    `25k_to_30k_change` = `25k_to_30k` * coef,
    `30k_to_35k_change` = `30k_to_35k` * coef,
    `35k_to_40k_change` = `35k_to_40k` * coef,
    `40k_to_45k_change` = `40k_to_45k` * coef,
    `45k_to_50k_change` = `45k_to_50k` * coef,
    `50k_to_60k_change` = `50k_to_60k` * coef,
    `60k_to_75k_change` = `60k_to_75k` * coef,
    `75k_to_100k_change` = `75k_to_100k` * coef,
    `100k_to_125k_change` = `100k_to_125k` * coef,
    `125k_to_150k_change` = `125k_to_150k` * coef,
    `150k_to_200k_change` = `150k_to_200k` * coef,
    `200k_or_more_change` = `200k_or_more` * coef) %>%
  # Summarizing the impact across all stations
  summarize(total_change_sum = sum(total_change),
    total_pop = sum(total),
    `less_than_10k_change_sum` = sum(`less_than_10k_change`),
    `10k_to_15k_change_sum` = sum(`10k_to_15k_change`),
    `15k_to_20k_change_sum` = sum(`15k_to_20k_change`),
    `20k_to_25k_change_sum` = sum(`20k_to_25k_change`),
    `25k_to_30k_change_sum` = sum(`25k_to_30k_change`),
    `30k_to_35k_change_sum` = sum(`30k_to_35k_change`),
    `35k_to_40k_change_sum` = sum(`35k_to_40k_change`),
    `40k_to_45k_change_sum` = sum(`40k_to_45k_change`),
    `45k_to_50k_change_sum` = sum(`45k_to_50k_change`),
    `50k_to_60k_change_sum` = sum(`50k_to_60k_change`),
    `60k_to_75k_change_sum` = sum(`60k_to_75k_change`),
    `75k_to_100k_change_sum` = sum(`75k_to_100k_change`),
    `100k_to_125k_change_sum` = sum(`100k_to_125k_change`),
    `125k_to_150k_change_sum` = sum(`125k_to_150k_change`),
    `150k_to_200k_change_sum` = sum(`150k_to_200k_change`),
    `200k_or_more_change_sum` = sum(`200k_or_more_change`),
    `less_than_10k` = sum(`less_than_10k`),
    `10k_to_15k` = sum(`10k_to_15k`),
    `15k_to_20k` = sum(`15k_to_20k`),
    `20k_to_25k` = sum(`20k_to_25k`),
    `25k_to_30k` = sum(`25k_to_30k`),
    `30k_to_35k` = sum(`30k_to_35k`),
    `35k_to_40k` = sum(`35k_to_40k`),
    `40k_to_45k` = sum(`40k_to_45k`),
    `45k_to_50k` = sum(`45k_to_50k`),
    `50k_to_60k` = sum(`50k_to_60k`),
    `60k_to_75k` = sum(`60k_to_75k`),
    `75k_to_100k` = sum(`75k_to_100k`),
    `100k_to_125k` = sum(`100k_to_125k`),
    `125k_to_150k` = sum(`125k_to_150k`),
    `150k_to_200k` = sum(`150k_to_200k`),
    `200k_or_more` = sum(`200k_or_more`)) %>%
  # Calculating the average change in pollution per individual in each demographic
  mutate(total_change_average = total_change_sum / total_pop,
    `less_than_10k_average` = `less_than_10k_change_sum` / `less_than_10k`,
    `10k_to_15k_average` = `10k_to_15k_change_sum` / `10k_to_15k`,
    `15k_to_20k_average` = `15k_to_20k_change_sum` / `15k_to_20k`,
    `20k_to_25k_average` = `20k_to_25k_change_sum` / `20k_to_25k`,
    `25k_to_30k_average` = `25k_to_30k_change_sum` / `25k_to_30k`,
    `30k_to_35k_average` = `30k_to_35k_change_sum` / `30k_to_35k`,
    `35k_to_40k_average` = `35k_to_40k_change_sum` / `35k_to_40k`,
    `40k_to_45k_average` = `40k_to_45k_change_sum` / `40k_to_45k`,
    `45k_to_50k_average` = `45k_to_50k_change_sum` / `45k_to_50k`,
    `50k_to_60k_average` = `50k_to_60k_change_sum` / `50k_to_60k`,
    `60k_to_75k_average` = `60k_to_75k_change_sum` / `60k_to_75k`,
    `75k_to_100k_average` = `75k_to_100k_change_sum` / `75k_to_100k`,
    `100k_to_125k_average` = `100k_to_125k_change_sum` / `100k_to_125k`,
    `125k_to_150k_average` = `125k_to_150k_change_sum` / `125k_to_150k`,
    `150k_to_200k_average` = `150k_to_200k_change_sum` / `150k_to_200k`,
    `200k_or_more_average` = `200k_or_more_change_sum` / `200k_or_more`)

# Create the final result table
final_result <- reduction_benefit %>%
  select(total_change_average,
    `less_than_10k_average`,
    `10k_to_15k_average`,
    `15k_to_20k_average`,
    `20k_to_25k_average`,
    `25k_to_30k_average`,
    `30k_to_35k_average`,
    `35k_to_40k_average`,
    `40k_to_45k_average`,
    `45k_to_50k_average`,
    `50k_to_60k_average`,
    `60k_to_75k_average`,
    `75k_to_100k_average`,
    `100k_to_125k_average`,
    `125k_to_150k_average`,
    `150k_to_200k_average`,
    `200k_or_more_average`)

# Display the table using kable
kable(final_result, digits = 2)

# Prepare data for plotting
final_result <- reduction_benefit %>%
  select(`less_than_10k_average`,
    `10k_to_15k_average`,
    `15k_to_20k_average`,
    `20k_to_25k_average`,
    `25k_to_30k_average`,
    `30k_to_35k_average`,
    `35k_to_40k_average`,
    `40k_to_45k_average`,
    `45k_to_50k_average`,
    `50k_to_60k_average`,
    `60k_to_75k_average`,
    `75k_to_100k_average`,
    `100k_to_125k_average`,
    `125k_to_150k_average`,
    `150k_to_200k_average`,
    `200k_or_more_average`)

income_groups <- c("<10k",
  "10k-15k",
  "15k-20k",
  "20k-25k",
  "25k-30k",
  "30k-35k",
  "35k-40k",
  "40k-45k",
  "45k-50k",
  "50k-60k",
  "60k-75k",
  "75k-100k",
  "100k-125k",
  "125k-150k",
  "150k-200k",
  ">200k")

# Transform data for plotting
plot_table <- t(final_result)
plot_table <- cbind(income_groups, plot_table)
plot_table <- as.data.frame(plot_table)
plot_table$V2 <- as.numeric(plot_table$V2)
plot_table$income_groups <- factor(plot_table$income_groups, levels = income_groups)

# Plot the data
png("average_income_change.png", width = 1000, height = 600, units = "px")
plot <- ggplot(data = plot_table, aes(x = income_groups, y = V2)) +
  geom_bar(stat = "identity", position = "dodge", fill = "#88a6ff", color = "#9e9e9e") +
  expand_limits(y = c(-0.3, 0)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    plot.title = element_text(size = 14)) + labs(x = "Income Groups", y = "Average Pollution Change")

# Print the plot

dev.off()
print(plot)
# all income groups seem to be getting a similar pollution reduction benefit on the individual level.

```

### PM2.5 Trends

```{r}
regression_stats <- summary(m1 <- lm(log(pm25) ~ MetroOpen:as.factor(station_ID) + construction + as.factor(day_of_week) + as.factor(month) + duringCAIR + Tair_f_tavg + Swnet_tavg + Lwnet_tavg + Qle_tavg + Qh_tavg + Snowf_tavg + Rainf_tavg + Qsm_tavg + SnowT_tavg + SWE_tavg + SnowDepth_tavg + Tair_f_tavg + Rainf_f_tavg + Wind_f_tavg + Qair_f_tavg + Psurf_f_tavg, data = metroOpen_df))

c <- coef(m1)
len_coef <- length(coef(m1))

# Get coefficients of the station-level effect
station_coef <- coef(m1)[(len_coef-(26-1)):len_coef]

# Convert coefficients to percentage change
station_coef_perc <- station_coef * 100

# Get p-values of the station-level effect (p < 0.05 is statistically significant)
pval <- summary(m1)$coefficients[,4][(len_coef-(26-1)):len_coef]

# Combine coefficients and p-values into a dataframe
station_data <- data.frame(coef = station_coef_perc, pval = pval)

# Load station coordinates
x <- vect(sample_latlon, crs = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
pm_sources <- vect("/Users/paditya9/teamCharlotte/PM2.5 ShapeFiles/new_pm_coords_sources.shp")

# Add coefficients to the spatial data
x$coef <- station_coef_perc
x$pval <- pval

# Define the breaks for the coefficients

breaks_interval <- c(-32, -30, -28, -26, -24, -22, -20)

# Create color palette with different shades of green (adjust green range as desired)
color_palette <- colorRampPalette(c("#2166AC", "#D1E5F0"))
colors <- color_palette(length(breaks_interval) - 1)




# Creating Buffer around stations
# Used Buffer Radius is 800 meters
pts_buffer <- buffer(x, width = 800)

# Creating Buffer for Map
extent <- buffer(aggregate(pts_buffer), width = 3000)

bg <- get_tiles(ext(extent), zoom = 11, provider = "Esri.WorldStreetMap")

png("final_pmchange_station.png", width = 1500, height = 1000, units = "px")

plot(bg)

plot(pts_buffer, 
     "coef",
     type = "interval",
     breaks = breaks_interval, 
     col = colors,
     cex.main = 2.125,
     plg = list( # parameters for drawing legend
       title = "Change in PM2.5 \n (in Percents)",
       title.cex = 1.5, # Legend title size
       cex = 1.5, # Legend text size
       inset = c(0.02, 0.02), # Legend inset (spacing from the plot)
       ncol = 1), # Number of columns in the legend
     add = TRUE)

# pch=19 gives filled circles
points(x, col = "black", pch = 19, cex = 2)

# pch=17 gives filled triangles
points(pm_sources, col = "#B2182B", pch = 17, cex = 2)

dev.off() 
```
